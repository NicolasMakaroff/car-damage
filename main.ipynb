{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFundanDataset(object):\n",
    "    def __init__(self,root,transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        #load every images, sorts them to ensure they're all aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root,\"PNGImages\")))) \n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root,\"PedMasks\"))))\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        # load images and masks\n",
    "        img_path = os.path.join(self.root,\"PNGImages\",self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root,\"PedMasks\",self.masks[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # no conversion of masks because each color correspond to a mask\n",
    "        mask = Image.open(mask_path)\n",
    "        # convert PIL images into a numpy array\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        # remove background\n",
    "        obj_ids = obj_ids[1:]\n",
    "        # binary encoding\n",
    "        masks = mask == obj_ids[:,None, None]\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_obj = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_obj):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        # convert to a torch tensor\n",
    "        boxes = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        \n",
    "        labels = torch.ones((num_obj,),dtype = torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype = torch.uint8)\n",
    "        \n",
    "        image_id =  torch.tensor([idx])\n",
    "        area = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
    "        # suppose all images are not crowd\n",
    "        iscrowd = torch.zeros((num_obj,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load a instance model pre-trained on coco metrics\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # get number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # replace it with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer,num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "dataset = PennFundanDataset('PennFudanPed', get_transform(train=True))\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, \n",
    "                                          shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "\n",
    "#Training\n",
    "images, targets =  next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images,targets)\n",
    "\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    num_classes = 2\n",
    "    dataset = PennFundanDataset('PennFudanPed', get_transform(train=True))\n",
    "    dataset_test = PennFundanDataset('PennFudanPed', get_transform(train=False))\n",
    "    \n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "    \n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "    \n",
    "    # let's train it for 10 epochs\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda7bdb38472b8447b1a3c551411def93ed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
