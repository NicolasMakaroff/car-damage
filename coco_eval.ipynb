{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "language": "python",
      "name": "python37364bitbaseconda7bdb38472b8447b1a3c551411def93ed"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "coco_eval.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolasMakaroff/car-damage/blob/master/coco_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JSu1YAukQRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import torch._six\n",
        "\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools.coco import COCO\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import utils\n",
        "\n",
        "\n",
        "class CocoEvaluator(object):\n",
        "    def __init__(self, coco_gt, iou_types):\n",
        "        assert isinstance(iou_types, (list, tuple))\n",
        "        coco_gt = copy.deepcopy(coco_gt)\n",
        "        self.coco_gt = coco_gt\n",
        "\n",
        "        self.iou_types = iou_types\n",
        "        self.coco_eval = {}\n",
        "        for iou_type in iou_types:\n",
        "            self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)\n",
        "\n",
        "        self.img_ids = []\n",
        "        self.eval_imgs = {k: [] for k in iou_types}\n",
        "\n",
        "    def update(self, predictions):\n",
        "        img_ids = list(np.unique(list(predictions.keys())))\n",
        "        self.img_ids.extend(img_ids)\n",
        "\n",
        "        for iou_type in self.iou_types:\n",
        "            results = self.prepare(predictions, iou_type)\n",
        "            coco_dt = loadRes(self.coco_gt, results) if results else COCO()\n",
        "            coco_eval = self.coco_eval[iou_type]\n",
        "\n",
        "            coco_eval.cocoDt = coco_dt\n",
        "            coco_eval.params.imgIds = list(img_ids)\n",
        "            img_ids, eval_imgs = evaluate(coco_eval)\n",
        "\n",
        "            self.eval_imgs[iou_type].append(eval_imgs)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for iou_type in self.iou_types:\n",
        "            self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)\n",
        "            create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])\n",
        "\n",
        "    def accumulate(self):\n",
        "        for coco_eval in self.coco_eval.values():\n",
        "            coco_eval.accumulate()\n",
        "\n",
        "    def summarize(self):\n",
        "        for iou_type, coco_eval in self.coco_eval.items():\n",
        "            print(\"IoU metric: {}\".format(iou_type))\n",
        "            coco_eval.summarize()\n",
        "\n",
        "    def prepare(self, predictions, iou_type):\n",
        "        if iou_type == \"bbox\":\n",
        "            return self.prepare_for_coco_detection(predictions)\n",
        "        elif iou_type == \"segm\":\n",
        "            return self.prepare_for_coco_segmentation(predictions)\n",
        "        elif iou_type == \"keypoints\":\n",
        "            return self.prepare_for_coco_keypoint(predictions)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown iou type {}\".format(iou_type))\n",
        "\n",
        "    def prepare_for_coco_detection(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = prediction[\"boxes\"]\n",
        "            boxes = convert_to_xywh(boxes).tolist()\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        \"bbox\": box,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, box in enumerate(boxes)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "    def prepare_for_coco_segmentation(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            scores = prediction[\"scores\"]\n",
        "            labels = prediction[\"labels\"]\n",
        "            masks = prediction[\"masks\"]\n",
        "\n",
        "            masks = masks > 0.5\n",
        "\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "            rles = [\n",
        "                mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=\"F\"))[0]\n",
        "                for mask in masks\n",
        "            ]\n",
        "            for rle in rles:\n",
        "                rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        \"segmentation\": rle,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, rle in enumerate(rles)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "    def prepare_for_coco_keypoint(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = prediction[\"boxes\"]\n",
        "            boxes = convert_to_xywh(boxes).tolist()\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "            keypoints = prediction[\"keypoints\"]\n",
        "            keypoints = keypoints.flatten(start_dim=1).tolist()\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        'keypoints': keypoint,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, keypoint in enumerate(keypoints)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
        "\n",
        "\n",
        "def merge(img_ids, eval_imgs):\n",
        "    all_img_ids = utils.all_gather(img_ids)\n",
        "    all_eval_imgs = utils.all_gather(eval_imgs)\n",
        "\n",
        "    merged_img_ids = []\n",
        "    for p in all_img_ids:\n",
        "        merged_img_ids.extend(p)\n",
        "\n",
        "    merged_eval_imgs = []\n",
        "    for p in all_eval_imgs:\n",
        "        merged_eval_imgs.append(p)\n",
        "\n",
        "    merged_img_ids = np.array(merged_img_ids)\n",
        "    merged_eval_imgs = np.concatenate(merged_eval_imgs, 2)\n",
        "\n",
        "    # keep only unique (and in sorted order) images\n",
        "    merged_img_ids, idx = np.unique(merged_img_ids, return_index=True)\n",
        "    merged_eval_imgs = merged_eval_imgs[..., idx]\n",
        "\n",
        "    return merged_img_ids, merged_eval_imgs\n",
        "\n",
        "\n",
        "def create_common_coco_eval(coco_eval, img_ids, eval_imgs):\n",
        "    img_ids, eval_imgs = merge(img_ids, eval_imgs)\n",
        "    img_ids = list(img_ids)\n",
        "    eval_imgs = list(eval_imgs.flatten())\n",
        "\n",
        "    coco_eval.evalImgs = eval_imgs\n",
        "    coco_eval.params.imgIds = img_ids\n",
        "    coco_eval._paramsEval = copy.deepcopy(coco_eval.params)\n",
        "\n",
        "\n",
        "#################################################################\n",
        "# From pycocotools, just removed the prints and fixed\n",
        "# a Python3 bug about unicode not defined\n",
        "#################################################################\n",
        "\n",
        "# Ideally, pycocotools wouldn't have hard-coded prints\n",
        "# so that we could avoid copy-pasting those two functions\n",
        "\n",
        "def createIndex(self):\n",
        "    # create index\n",
        "    # print('creating index...')\n",
        "    anns, cats, imgs = {}, {}, {}\n",
        "    imgToAnns, catToImgs = defaultdict(list), defaultdict(list)\n",
        "    if 'annotations' in self.dataset:\n",
        "        for ann in self.dataset['annotations']:\n",
        "            imgToAnns[ann['image_id']].append(ann)\n",
        "            anns[ann['id']] = ann\n",
        "\n",
        "    if 'images' in self.dataset:\n",
        "        for img in self.dataset['images']:\n",
        "            imgs[img['id']] = img\n",
        "\n",
        "    if 'categories' in self.dataset:\n",
        "        for cat in self.dataset['categories']:\n",
        "            cats[cat['id']] = cat\n",
        "\n",
        "    if 'annotations' in self.dataset and 'categories' in self.dataset:\n",
        "        for ann in self.dataset['annotations']:\n",
        "            catToImgs[ann['category_id']].append(ann['image_id'])\n",
        "\n",
        "    # print('index created!')\n",
        "\n",
        "    # create class members\n",
        "    self.anns = anns\n",
        "    self.imgToAnns = imgToAnns\n",
        "    self.catToImgs = catToImgs\n",
        "    self.imgs = imgs\n",
        "    self.cats = cats\n",
        "\n",
        "\n",
        "maskUtils = mask_util\n",
        "\n",
        "\n",
        "def loadRes(self, resFile):\n",
        "    \"\"\"\n",
        "    Load result file and return a result api object.\n",
        "    :param   resFile (str)     : file name of result file\n",
        "    :return: res (obj)         : result api object\n",
        "    \"\"\"\n",
        "    res = COCO()\n",
        "    res.dataset['images'] = [img for img in self.dataset['images']]\n",
        "\n",
        "    # print('Loading and preparing results...')\n",
        "    # tic = time.time()\n",
        "    if isinstance(resFile, torch._six.string_classes):\n",
        "        anns = json.load(open(resFile))\n",
        "    elif type(resFile) == np.ndarray:\n",
        "        anns = self.loadNumpyAnnotations(resFile)\n",
        "    else:\n",
        "        anns = resFile\n",
        "    assert type(anns) == list, 'results in not an array of objects'\n",
        "    annsImgIds = [ann['image_id'] for ann in anns]\n",
        "    assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n",
        "        'Results do not correspond to current coco set'\n",
        "    if 'caption' in anns[0]:\n",
        "        imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n",
        "        res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n",
        "        for id, ann in enumerate(anns):\n",
        "            ann['id'] = id + 1\n",
        "    elif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n",
        "        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "        for id, ann in enumerate(anns):\n",
        "            bb = ann['bbox']\n",
        "            x1, x2, y1, y2 = [bb[0], bb[0] + bb[2], bb[1], bb[1] + bb[3]]\n",
        "            if 'segmentation' not in ann:\n",
        "                ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
        "            ann['area'] = bb[2] * bb[3]\n",
        "            ann['id'] = id + 1\n",
        "            ann['iscrowd'] = 0\n",
        "    elif 'segmentation' in anns[0]:\n",
        "        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "        for id, ann in enumerate(anns):\n",
        "            # now only support compressed RLE format as segmentation results\n",
        "            ann['area'] = maskUtils.area(ann['segmentation'])\n",
        "            if 'bbox' not in ann:\n",
        "                ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n",
        "            ann['id'] = id + 1\n",
        "            ann['iscrowd'] = 0\n",
        "    elif 'keypoints' in anns[0]:\n",
        "        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
        "        for id, ann in enumerate(anns):\n",
        "            s = ann['keypoints']\n",
        "            x = s[0::3]\n",
        "            y = s[1::3]\n",
        "            x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)\n",
        "            ann['area'] = (x2 - x1) * (y2 - y1)\n",
        "            ann['id'] = id + 1\n",
        "            ann['bbox'] = [x1, y1, x2 - x1, y2 - y1]\n",
        "    # print('DONE (t={:0.2f}s)'.format(time.time()- tic))\n",
        "\n",
        "    res.dataset['annotations'] = anns\n",
        "    createIndex(res)\n",
        "    return res\n",
        "\n",
        "\n",
        "def evaluate(self):\n",
        "    '''\n",
        "    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n",
        "    :return: None\n",
        "    '''\n",
        "    # tic = time.time()\n",
        "    # print('Running per image evaluation...')\n",
        "    p = self.params\n",
        "    # add backward compatibility if useSegm is specified in params\n",
        "    if p.useSegm is not None:\n",
        "        p.iouType = 'segm' if p.useSegm == 1 else 'bbox'\n",
        "        print('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType))\n",
        "    # print('Evaluate annotation type *{}*'.format(p.iouType))\n",
        "    p.imgIds = list(np.unique(p.imgIds))\n",
        "    if p.useCats:\n",
        "        p.catIds = list(np.unique(p.catIds))\n",
        "    p.maxDets = sorted(p.maxDets)\n",
        "    self.params = p\n",
        "\n",
        "    self._prepare()\n",
        "    # loop through images, area range, max detection number\n",
        "    catIds = p.catIds if p.useCats else [-1]\n",
        "\n",
        "    if p.iouType == 'segm' or p.iouType == 'bbox':\n",
        "        computeIoU = self.computeIoU\n",
        "    elif p.iouType == 'keypoints':\n",
        "        computeIoU = self.computeOks\n",
        "    self.ious = {\n",
        "        (imgId, catId): computeIoU(imgId, catId)\n",
        "        for imgId in p.imgIds\n",
        "        for catId in catIds}\n",
        "\n",
        "    evaluateImg = self.evaluateImg\n",
        "    maxDet = p.maxDets[-1]\n",
        "    evalImgs = [\n",
        "        evaluateImg(imgId, catId, areaRng, maxDet)\n",
        "        for catId in catIds\n",
        "        for areaRng in p.areaRng\n",
        "        for imgId in p.imgIds\n",
        "    ]\n",
        "    # this is NOT in the pycocotools code, but could be done outside\n",
        "    evalImgs = np.asarray(evalImgs).reshape(len(catIds), len(p.areaRng), len(p.imgIds))\n",
        "    self._paramsEval = copy.deepcopy(self.params)\n",
        "    # toc = time.time()\n",
        "    # print('DONE (t={:0.2f}s).'.format(toc-tic))\n",
        "    return p.imgIds, evalImgs\n",
        "\n",
        "#################################################################\n",
        "# end of straight copy from pycocotools, just removing the prints\n",
        "#################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}