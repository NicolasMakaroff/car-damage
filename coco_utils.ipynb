{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "language": "python",
      "name": "python37364bitbaseconda7bdb38472b8447b1a3c551411def93ed"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "coco_utils.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolasMakaroff/car-damage/blob/master/coco_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP1RMVG6kWaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "\n",
        "from pycocotools import mask as coco_mask\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import transforms as T\n",
        "\n",
        "\n",
        "class FilterAndRemapCocoCategories(object):\n",
        "    def __init__(self, categories, remap=True):\n",
        "        self.categories = categories\n",
        "        self.remap = remap\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        anno = target[\"annotations\"]\n",
        "        anno = [obj for obj in anno if obj[\"category_id\"] in self.categories]\n",
        "        if not self.remap:\n",
        "            target[\"annotations\"] = anno\n",
        "            return image, target\n",
        "        anno = copy.deepcopy(anno)\n",
        "        for obj in anno:\n",
        "            obj[\"category_id\"] = self.categories.index(obj[\"category_id\"])\n",
        "        target[\"annotations\"] = anno\n",
        "        return image, target\n",
        "\n",
        "\n",
        "def convert_coco_poly_to_mask(segmentations, height, width):\n",
        "    masks = []\n",
        "    for polygons in segmentations:\n",
        "        rles = coco_mask.frPyObjects(polygons, height, width)\n",
        "        mask = coco_mask.decode(rles)\n",
        "        if len(mask.shape) < 3:\n",
        "            mask = mask[..., None]\n",
        "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
        "        mask = mask.any(dim=2)\n",
        "        masks.append(mask)\n",
        "    if masks:\n",
        "        masks = torch.stack(masks, dim=0)\n",
        "    else:\n",
        "        masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
        "    return masks\n",
        "\n",
        "\n",
        "class ConvertCocoPolysToMask(object):\n",
        "    def __call__(self, image, target):\n",
        "        w, h = image.size\n",
        "\n",
        "        image_id = target[\"image_id\"]\n",
        "        image_id = torch.tensor([image_id])\n",
        "\n",
        "        anno = target[\"annotations\"]\n",
        "\n",
        "        anno = [obj for obj in anno if obj['iscrowd'] == 0]\n",
        "\n",
        "        boxes = [obj[\"bbox\"] for obj in anno]\n",
        "        # guard against no boxes via resizing\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
        "        boxes[:, 2:] += boxes[:, :2]\n",
        "        boxes[:, 0::2].clamp_(min=0, max=w)\n",
        "        boxes[:, 1::2].clamp_(min=0, max=h)\n",
        "\n",
        "        classes = [obj[\"category_id\"] for obj in anno]\n",
        "        classes = torch.tensor(classes, dtype=torch.int64)\n",
        "\n",
        "        segmentations = [obj[\"segmentation\"] for obj in anno]\n",
        "        masks = convert_coco_poly_to_mask(segmentations, h, w)\n",
        "\n",
        "        keypoints = None\n",
        "        if anno and \"keypoints\" in anno[0]:\n",
        "            keypoints = [obj[\"keypoints\"] for obj in anno]\n",
        "            keypoints = torch.as_tensor(keypoints, dtype=torch.float32)\n",
        "            num_keypoints = keypoints.shape[0]\n",
        "            if num_keypoints:\n",
        "                keypoints = keypoints.view(num_keypoints, -1, 3)\n",
        "\n",
        "        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])\n",
        "        boxes = boxes[keep]\n",
        "        classes = classes[keep]\n",
        "        masks = masks[keep]\n",
        "        if keypoints is not None:\n",
        "            keypoints = keypoints[keep]\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = classes\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        if keypoints is not None:\n",
        "            target[\"keypoints\"] = keypoints\n",
        "\n",
        "        # for conversion to coco api\n",
        "        area = torch.tensor([obj[\"area\"] for obj in anno])\n",
        "        iscrowd = torch.tensor([obj[\"iscrowd\"] for obj in anno])\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "def _coco_remove_images_without_annotations(dataset, cat_list=None):\n",
        "    def _has_only_empty_bbox(anno):\n",
        "        return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
        "\n",
        "    def _count_visible_keypoints(anno):\n",
        "        return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
        "\n",
        "    min_keypoints_per_image = 10\n",
        "\n",
        "    def _has_valid_annotation(anno):\n",
        "        # if it's empty, there is no annotation\n",
        "        if len(anno) == 0:\n",
        "            return False\n",
        "        # if all boxes have close to zero area, there is no annotation\n",
        "        if _has_only_empty_bbox(anno):\n",
        "            return False\n",
        "        # keypoints task have a slight different critera for considering\n",
        "        # if an annotation is valid\n",
        "        if \"keypoints\" not in anno[0]:\n",
        "            return True\n",
        "        # for keypoint detection tasks, only consider valid images those\n",
        "        # containing at least min_keypoints_per_image\n",
        "        if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    assert isinstance(dataset, torchvision.datasets.CocoDetection)\n",
        "    ids = []\n",
        "    for ds_idx, img_id in enumerate(dataset.ids):\n",
        "        ann_ids = dataset.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
        "        anno = dataset.coco.loadAnns(ann_ids)\n",
        "        if cat_list:\n",
        "            anno = [obj for obj in anno if obj[\"category_id\"] in cat_list]\n",
        "        if _has_valid_annotation(anno):\n",
        "            ids.append(ds_idx)\n",
        "\n",
        "    dataset = torch.utils.data.Subset(dataset, ids)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def convert_to_coco_api(ds):\n",
        "    coco_ds = COCO()\n",
        "    # annotation IDs need to start at 1, not 0, see torchvision issue #1530\n",
        "    ann_id = 1\n",
        "    dataset = {'images': [], 'categories': [], 'annotations': []}\n",
        "    categories = set()\n",
        "    for img_idx in range(len(ds)):\n",
        "        # find better way to get target\n",
        "        # targets = ds.get_annotations(img_idx)\n",
        "        img, targets = ds[img_idx]\n",
        "        image_id = targets[\"image_id\"].item()\n",
        "        img_dict = {}\n",
        "        img_dict['id'] = image_id\n",
        "        img_dict['height'] = img.shape[-2]\n",
        "        img_dict['width'] = img.shape[-1]\n",
        "        dataset['images'].append(img_dict)\n",
        "        bboxes = targets[\"boxes\"]\n",
        "        bboxes[:, 2:] -= bboxes[:, :2]\n",
        "        bboxes = bboxes.tolist()\n",
        "        labels = targets['labels'].tolist()\n",
        "        areas = targets['area'].tolist()\n",
        "        iscrowd = targets['iscrowd'].tolist()\n",
        "        if 'masks' in targets:\n",
        "            masks = targets['masks']\n",
        "            # make masks Fortran contiguous for coco_mask\n",
        "            masks = masks.permute(0, 2, 1).contiguous().permute(0, 2, 1)\n",
        "        if 'keypoints' in targets:\n",
        "            keypoints = targets['keypoints']\n",
        "            keypoints = keypoints.reshape(keypoints.shape[0], -1).tolist()\n",
        "        num_objs = len(bboxes)\n",
        "        for i in range(num_objs):\n",
        "            ann = {}\n",
        "            ann['image_id'] = image_id\n",
        "            ann['bbox'] = bboxes[i]\n",
        "            ann['category_id'] = labels[i]\n",
        "            categories.add(labels[i])\n",
        "            ann['area'] = areas[i]\n",
        "            ann['iscrowd'] = iscrowd[i]\n",
        "            ann['id'] = ann_id\n",
        "            if 'masks' in targets:\n",
        "                ann[\"segmentation\"] = coco_mask.encode(masks[i].numpy())\n",
        "            if 'keypoints' in targets:\n",
        "                ann['keypoints'] = keypoints[i]\n",
        "                ann['num_keypoints'] = sum(k != 0 for k in keypoints[i][2::3])\n",
        "            dataset['annotations'].append(ann)\n",
        "            ann_id += 1\n",
        "    dataset['categories'] = [{'id': i} for i in sorted(categories)]\n",
        "    coco_ds.dataset = dataset\n",
        "    coco_ds.createIndex()\n",
        "    return coco_ds\n",
        "\n",
        "\n",
        "def get_coco_api_from_dataset(dataset):\n",
        "    for _ in range(10):\n",
        "        if isinstance(dataset, torchvision.datasets.CocoDetection):\n",
        "            break\n",
        "        if isinstance(dataset, torch.utils.data.Subset):\n",
        "            dataset = dataset.dataset\n",
        "    if isinstance(dataset, torchvision.datasets.CocoDetection):\n",
        "        return dataset.coco\n",
        "    return convert_to_coco_api(dataset)\n",
        "\n",
        "\n",
        "class CocoDetection(torchvision.datasets.CocoDetection):\n",
        "    def __init__(self, img_folder, ann_file, transforms):\n",
        "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
        "        self._transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        target = dict(image_id=image_id, annotations=target)\n",
        "        if self._transforms is not None:\n",
        "            img, target = self._transforms(img, target)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def get_coco(root, image_set, transforms, mode='instances'):\n",
        "    anno_file_template = \"{}_{}2017.json\"\n",
        "    PATHS = {\n",
        "        \"train\": (\"train2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"train\"))),\n",
        "        \"val\": (\"val2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"val\"))),\n",
        "        # \"train\": (\"val2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"val\")))\n",
        "    }\n",
        "\n",
        "    t = [ConvertCocoPolysToMask()]\n",
        "\n",
        "    if transforms is not None:\n",
        "        t.append(transforms)\n",
        "    transforms = T.Compose(t)\n",
        "\n",
        "    img_folder, ann_file = PATHS[image_set]\n",
        "    img_folder = os.path.join(root, img_folder)\n",
        "    ann_file = os.path.join(root, ann_file)\n",
        "\n",
        "    dataset = CocoDetection(img_folder, ann_file, transforms=transforms)\n",
        "\n",
        "    if image_set == \"train\":\n",
        "        dataset = _coco_remove_images_without_annotations(dataset)\n",
        "\n",
        "    # dataset = torch.utils.data.Subset(dataset, [i for i in range(500)])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_coco_kp(root, image_set, transforms):\n",
        "    return get_coco(root, image_set, transforms, mode=\"person_keypoints\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}